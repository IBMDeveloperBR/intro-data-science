{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center'>Intro Data Science<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Para manipulação numérica\n",
    "import pandas as pd # Para manipulação do dataset\n",
    "import matplotlib.pyplot as plt # Visualização de gráficos\n",
    "import seaborn as sns # Visualização de gráficos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos explorar o dataset sobre Brasil. Nele temos informação geográficas como:\n",
    "* Popoulação\n",
    "* IDH\n",
    "* PIB *Per capta*\n",
    "* etc\n",
    "\n",
    "Alêm dos dados geográficos, também estão presentes no dataset alguns dados mais variados como:\n",
    "* Presença de Uber\n",
    "* Quantidade de McDonald's\n",
    "* Quantidade de Wal-Mart\n",
    "* etc\n",
    "\n",
    "\n",
    "Vamos começar pela leitura do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "credentials_1 = {\n",
    "    'IAM_SERVICE_ID': 'Let me take you down',\n",
    "    'IBM_API_KEY_ID': 'Cause I`m going to Strawberry Fields',\n",
    "    'ENDPOINT': 'Nothing is real',\n",
    "    'IBM_AUTH_ENDPOINT': 'And nothing to get hung about',\n",
    "    'BUCKET': 'Strawberry Fields forever',\n",
    "    'FILE': 'BRAZIL_CITIES.csv'\n",
    "}\n",
    "\n",
    "client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id=credentials_1['IBM_API_KEY_ID'],\n",
    "    ibm_auth_endpoint=credentials_1['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=credentials_1['ENDPOINT'])\n",
    "\n",
    "\n",
    "with open('BRAZIL_CITIES.csv', 'wb') as data:\n",
    "    client.download_fileobj(credentials_1['BUCKET'], 'BRAZIL_CITIES.csv', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = pd.read_csv('./BRAZIL_CITIES.csv', sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com dataset disponível para uso, vamos verificar o conteûdo do mesmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados parecem corretos, mas vamos dar uma olhanda mais a fundo para nos certificamos de que os tipos estão corretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Olhando para o dataset e verificandos os tipos dados que nos foi entregue, fica evidente que antes de iniciarmos qualquer trabalho de analise devemos corrigir e limpar imperfeições do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrigeTipo(d, c, t):\n",
    "    return d[[c]].astype(t)\n",
    "\n",
    "\n",
    "df_01[['IDHM']] = corrigeTipo(df_01, 'IDHM', 'float')\n",
    "df_01[['IDHM_Renda']] = corrigeTipo(df_01, 'IDHM_Renda', 'float')\n",
    "df_01[['IDHM_Longevidade']] = corrigeTipo(df_01, 'IDHM_Longevidade', 'float')\n",
    "df_01[['IDHM_Educacao']] = corrigeTipo(df_01, 'IDHM_Educacao', 'float')\n",
    "df_01[['LONG']] = corrigeTipo(df_01, 'LONG', 'float')\n",
    "df_01[['LAT']] = corrigeTipo(df_01, 'LAT', 'float')\n",
    "df_01[['ALT']] = corrigeTipo(df_01, 'ALT', 'float')\n",
    "df_01[['GVA_AGROPEC']] = corrigeTipo(df_01, 'GVA_AGROPEC', 'float')\n",
    "df_01[['GVA_INDUSTRY']] = corrigeTipo(df_01, 'GVA_INDUSTRY', 'float')\n",
    "df_01[['GVA_SERVICES']] = corrigeTipo(df_01, 'GVA_SERVICES', 'float')\n",
    "df_01[['GVA_PUBLIC']] = corrigeTipo(df_01, 'GVA_PUBLIC', 'float')\n",
    "df_01[[' GVA_TOTAL ']] = corrigeTipo(df_01, ' GVA_TOTAL ', 'float')\n",
    "df_01[['TAXES']] = corrigeTipo(df_01, 'TAXES', 'float')\n",
    "df_01[['GDP']] = corrigeTipo(df_01, 'GDP', 'float')\n",
    "df_01[['POP_GDP']] = corrigeTipo(df_01, 'POP_GDP', 'float')\n",
    "df_01[['GDP_CAPITA']] = corrigeTipo(df_01, 'GDP_CAPITA', 'float')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para corrigir à área teremos que ser uma pouco mais criativos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def castStrNumber(s):\n",
    "    if len(s) == 2:\n",
    "        return s[0]+s[1]\n",
    "    elif len(s) > 2:\n",
    "        return s[0]+castStrNumber(s[1:len(s)])\n",
    "    else:\n",
    "        return s[0]\n",
    "\n",
    "area = []\n",
    "for i,j in df_01[['AREA']].iterrows():\n",
    "    if type(j[0]) == str:\n",
    "        area.append(castStrNumber(j[0].split(',')))\n",
    "    else:\n",
    "        area.append(j[0])\n",
    "    \n",
    "df_01[['AREA']] = np.array(area)\n",
    "df_01[['AREA']] = df_01[['AREA']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.fillna(0., inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora parece tudo correto com relação ao tipo dos dados, então vamos explorar um pouco mais do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01[\"STATE\"].value_counts().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com dataset limpo e adequado, agora podemos começar a explorar algumas métricas. Vamos verificar a quintidade de municípios por estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01[\"STATE\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01[['STATE', 'CITY']].groupby('STATE').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos começar a explorar um pouco mais gerar visualizações para os nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskLat = df_01[\"LONG\"] != 0\n",
    "maskLong = df_01[\"LAT\"] != 0 \n",
    "\n",
    "x = df_01[maskLat&maskLong][\"LONG\"]\n",
    "y = df_01[maskLat&maskLong][\"LAT\"]\n",
    "z = df_01[maskLat&maskLong][\"IDHM\"]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Longitude vs Latitude - Localização das cidades do Brasil\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.scatter(x, y, s=z, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_01[maskLat&maskLong][\"LONG\"]\n",
    "y = df_01[maskLat&maskLong][\"LAT\"]\n",
    "z = df_01[maskLat&maskLong][\"ESTIMATED_POP\"]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Longitude vs Latitude - Localização da população do Brasil\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.scatter(x, y, s=z/5000, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um pouquinho de miscelânia agora, vamos descobrir onde os Wal-Mart do Brasil estão, ou pelo menos estavam..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_01[maskLat&maskLong][\"LONG\"]\n",
    "y = df_01[maskLat&maskLong][\"LAT\"]\n",
    "z = df_01[maskLat&maskLong][\"WAL-MART\"]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Longitude x Latitude - Localização dos Wal Mart do Brasil\")\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.scatter(x, y, s=z, alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar novas métricas agora. O classificar as cidades que possuem os serviços de Uber, MaCdonald's e Walmart de acordo com as seguintes categorias:\n",
    "* A -> Cidade possui os três serviços\n",
    "* B -> Cidade possui Mac e Walmart\n",
    "* C -> Cidade possui Uber e Walmart\n",
    "* D -> Cidade possui Uber e Mac\n",
    "* E -> Cidade possui somente Uber\n",
    "* F -> Cidade possui somente Mac\n",
    "* G -> Cidade possui somente walmart\n",
    "* Z -> Cidade não possui nenhum dos serviços\n",
    "\n",
    "Para isso vamos iterar o dataset analisando linha a linha para gerar a categoria final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = []\n",
    "for i,j in df_01[['UBER', 'MAC', 'WAL-MART']].iterrows():\n",
    "    if j[0] != 0 and j[1] != 0 and j[2] != 0:\n",
    "        cat.append('A') # Possui os tres servicos\n",
    "    elif j[0] == 0 and j[1] != 0 and j[2] != 0:\n",
    "        cat.append('B') # somente Mac e Walmart\n",
    "    elif j[0] != 0 and j[1] == 0 and j[2] != 0:\n",
    "        cat.append('C') # somente Uber e Walmart\n",
    "    elif j[0] != 0 and j[1] != 0 and j[2] == 0:\n",
    "        cat.append('D') # somente Uber e Mac\n",
    "    elif j[0] != 0 and j[1] == 0 and j[2] == 0:\n",
    "        cat.append('E') # somente Uber\n",
    "    elif j[0] == 0 and j[1] != 0 and j[2] == 0:\n",
    "        cat.append('F')\n",
    "    elif j[0] == 0 and j[1] == 0 and j[2] != 0:\n",
    "        cat.append('G') # somente walmart\n",
    "    else:\n",
    "        cat.append('Z')\n",
    "\n",
    "df_01.insert(81, 'UMW', cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskCat = df_01['UMW'] != 0\n",
    "sns.lmplot(x='LONG',\n",
    "           y='LAT',\n",
    "           data=df_01[maskLong&maskLat&maskCat],\n",
    "           fit_reg=False,\n",
    "           hue='UMW',\n",
    "           legend=True,\n",
    "           scatter_kws={'s':30},\n",
    "           height=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E como isso divide entre os município do país."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df_01[maskLong&maskLat&maskCat]\n",
    "\n",
    "tot = cat[['CITY', 'UMW']].groupby('UMW').count().sum().values[0]\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z']\n",
    "A = np.array(cat[['CITY', 'UMW']].groupby('UMW').count()).reshape(8)/np.array(tot)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Distribuição das categorias')\n",
    "wedges, texts, autotexts = plt.pie(A, labels=labels, autopct='%.1f%%')\n",
    "plt.legend(wedges, ['A - Possui os três serviços', 'B - Mac e Walmart', 'C - Uber e Walmart', 'D - Uber e Mac', 'E - Uber', 'F - Mac', 'G - Walmart', 'Z - Nenhum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E a qual a parcela da população com acesso a estes serviços ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = cat[['ESTIMATED_POP', 'UMW']].sum().values[0]\n",
    "cat[['ESTIMATED_POP', 'UMW']].groupby('UMW').sum()\n",
    "\n",
    "labels = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'Z']\n",
    "A = np.array(cat[['ESTIMATED_POP', 'UMW']].groupby('UMW').sum()).reshape(8)/np.array(tot)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title('Distribuição das categorias')\n",
    "wedges, texts, autotexts = plt.pie(A, labels=labels, autopct='%.1f%%')\n",
    "plt.legend(wedges, ['A - Possui os três serviços', 'B - Mac e Walmart', 'C - Uber e Walmart', 'D - Uber e Mac', 'E - Uber', 'F - Mac', 'G - Walmart', 'Z - Nenhum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos explorar um pouco agora o quão sensível algumas variáveis são as outras. Podemos fazer isso por meio de um mapa de calor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID01 = df_01[['ESTIMATED_POP', 'AREA', 'IDHM', 'GVA_AGROPEC', 'GVA_INDUSTRY', 'GVA_SERVICES', 'GVA_PUBLIC', 'POP_GDP']]\n",
    "\n",
    "tot = np.array(ID01['GVA_AGROPEC'])+np.array(ID01['GVA_INDUSTRY'])+np.array(ID01['GVA_SERVICES'])+np.array(ID01['GVA_PUBLIC'])\n",
    "gva_agro = [j[0]/(j.sum()) if j[0] != 0 else 0 for i,j in ID01[['GVA_AGROPEC', 'GVA_INDUSTRY', 'GVA_SERVICES', 'GVA_PUBLIC']].iterrows()]\n",
    "gva_ind = [j[1]/(j.sum()) if j[1] != 0 else 0 for i,j in ID01[['GVA_AGROPEC', 'GVA_INDUSTRY', 'GVA_SERVICES', 'GVA_PUBLIC']].iterrows()]\n",
    "gva_serv = [j[2]/(j.sum()) if j[2] != 0 else 0 for i,j in ID01[['GVA_AGROPEC', 'GVA_INDUSTRY', 'GVA_SERVICES', 'GVA_PUBLIC']].iterrows()]\n",
    "gva_pub = [j[3]/(j.sum()) if j[3] != 0 else 0 for i,j in ID01[['GVA_AGROPEC', 'GVA_INDUSTRY', 'GVA_SERVICES', 'GVA_PUBLIC']].iterrows()]\n",
    "\n",
    "ID01.insert(8, 'GVA_AGROPEC_%', gva_agro)\n",
    "ID01.insert(9, 'GVA_INDUSTRY_%', gva_ind)\n",
    "ID01.insert(10, 'GVA_SERVICES_%', gva_serv)\n",
    "ID01.insert(11, 'GVA_PUBLIC_%', gva_pub)\n",
    "\n",
    "corrmat = ID01.corr()\n",
    "top_corr_features = corrmat.index\n",
    "plt.figure(figsize=(20,20))\n",
    "#plot heat map\n",
    "g=sns.heatmap(ID01[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que existe uma correlação forte entre algumas variáveis, logo podemos montar um modelo de regressão linear para entendermos como um variável se comporta em função da outra.\n",
    "\n",
    "Para isso vamos precisar de mais algumas bibliotecas para que possamos cumprir essa missão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos deixar bem separado nosso domínio e contra domínio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ID01[['GVA_INDUSTRY', 'GVA_SERVICES', 'GVA_PUBLIC']]\n",
    "Y = ID01[['ESTIMATED_POP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos separa o conjuntos de dados em dois, um para treinarmento e outro para teste do modelo criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos tentar uma fução que descreve bem os dados. A priemira será a regresão linear: LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos alimetar o modelo com dados obter os coeficienes para cada eixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Score(R2) do modelo para o conjunto de treino: {}'.format(reg.score(X_train,Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta forms a equação fica $$f(x,y,z) = cof1x + cof2y + cof3z + int$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('f(x,y,z) = {}x + {}y + {}z + {}'.format(reg.coef_[0][0], reg.coef_[0][1], reg.coef_[0][2], reg.intercept_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com isso descobrimos a melhor função que descreve os dados obtidos para o modelo de LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Erro quadrado médio: {}'.format(mean_squared_error(Y_test, pred)))\n",
    "print('R2 real: {}'.format(r2_score(Y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos testar agora uma regressão com SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_svm = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Erro quadrado médio: {}'.format(mean_squared_error(Y_test, pred_svm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('R2 real: {}'.format(r2_score(Y_test, pred_svm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos testar uma com Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arv = tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_arv = arv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Erro quadrado médio: {}'.format(mean_squared_error(Y_test, pred_arv)))\n",
    "print('R2 real: {}'.format(r2_score(Y_test, pred_arv)))\n",
    "print(Y_test.iloc[293].values, arv.predict([X_test.iloc[293].values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credenciais do Watson Machine Learning\n",
    "wml_credentials  = {\n",
    "  \"apikey\": \"Picture yourself in a boat on a river\",\n",
    "  \"iam_apikey_description\": \"With tangerine trees and marmalade skies\",\n",
    "  \"iam_apikey_name\": \"Somebody calls you, you answer quite slowly\",\n",
    "  \"iam_role_crn\": \"A girl with kaleidoscope eyes\",\n",
    "  \"iam_serviceid_crn\": \"Cellophane flowers of yellow and green\",\n",
    "  \"instance_id\": \"Towering over your head\",\n",
    "  \"password\": \"Look for the girl with the sun in her eyes\",\n",
    "  \"url\": \"And she's gone\",\n",
    "  \"username\": \"Lucy in the sky with diamonds\"\n",
    "}\n",
    "client = WatsonMachineLearningAPIClient( wml_credentials )\n",
    "\n",
    "# Definição de metadados do modelo (versao de python, framework, libs e etc)\n",
    "metadata = {\n",
    "    client.repository.ModelMetaNames.NAME              : 'Intro Data Science',\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME    : 'scikit-learn',\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION : '0.19',\n",
    "    client.repository.ModelMetaNames.RUNTIME_NAME      : 'python',\n",
    "    client.repository.ModelMetaNames.RUNTIME_VERSION   : '3.6'\n",
    "}\n",
    "\n",
    "\n",
    "# Conexão com o WML\n",
    "model_details = client.repository.store_model( reg, meta_props=metadata, training_data=None )\n",
    "\n",
    "# Deploy do modelo\n",
    "model_id = model_details[\"metadata\"][\"guid\"]\n",
    "model_deployment_details = client.deployments.create( artifact_uid=model_id, name=\"Ha\" )\n",
    "\n",
    "# Retrieve da URL da API para consumo da mesma\n",
    "model_endpoint_url = client.deployments.get_scoring_url( model_deployment_details )\n",
    "print(\"A URL de chamada da sua API é : \",model_endpoint_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referências \n",
    "\n",
    "\n",
    "- [Dataset](https://www.kaggle.com/crisparada/brazilian-cities/version/7)\n",
    "- [Notebook guia](https://www.kaggle.com/crisparada/brazilian-cities-a-simple-exploration)\n",
    "- [Pandas](https://pandas.pydata.org/)\n",
    "- [Numpy](https://numpy.org/)\n",
    "- [Matplotlib](https://matplotlib.org/)\n",
    "- [Seaborn](https://seaborn.pydata.org/)\n",
    "- [Scikit-Learn](https://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style='text-align:center'>Obrigado!<h1>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
